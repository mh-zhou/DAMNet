{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raytrack/.conda/envs/torch1121/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import trange, tqdm\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import utilities as UT\n",
    "from ranksvm import get_dynamic_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities as UT\n",
    "from ranksvm import get_dynamic_image\n",
    "\n",
    "LABEL_PATH = '/home/raytrack/.jupyter/Dynamic/Preprocessed'\n",
    "\n",
    "def prep_data(LABEL_PATH, TEST_NUM):\n",
    "    # This function is used to prepare train/test labels for 5-fold cross-validation\n",
    "    TEST_LABEL = f'{LABEL_PATH}/fold_CNvsAD_{TEST_NUM}.csv'\n",
    "\n",
    "    # combine train labels\n",
    "    filenames = [f'{LABEL_PATH}/fold_CNvsAD_{i}.csv' for i in range(5)]\n",
    "    filenames.remove(TEST_LABEL)\n",
    "\n",
    "    combined_train_list_path = f'{LABEL_PATH}/combined_train_list_{TEST_NUM}.csv'\n",
    "    with open(combined_train_list_path, 'w') as combined_train_list:\n",
    "        for fold in filenames:\n",
    "            for line in open(fold, 'r'):\n",
    "                combined_train_list.write(line)\n",
    "    TRAIN_LABEL = combined_train_list_path\n",
    "    \n",
    "    return TRAIN_LABEL, TEST_LABEL\n",
    "\n",
    "\n",
    "class Dataset_Early_Fusion(Dataset):\n",
    "    def __init__(self, label_file):\n",
    "        self.files = UT.read_csv(label_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        temp = self.files[idx]\n",
    "        full_path = temp[0]\n",
    "\n",
    "        label_str = full_path.split('/')[-3]  # Get the label string from the file path\n",
    "        if label_str == 'CN':\n",
    "            label = 0\n",
    "        elif label_str == 'AD':\n",
    "            label = 1\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected label: {label_str}')\n",
    "\n",
    "        im = np.load(full_path)\n",
    "        im = get_dynamic_image(im)\n",
    "        im = np.expand_dims(im, 0)\n",
    "        im = np.concatenate([im, im, im], 0)\n",
    "\n",
    "        return im, label, full_path  # label is now an int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义全局注意力模块（GAM）\n",
    "class GAM_Attention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(GAM_Attention, self).__init__()\n",
    "\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)  # 全局平均池化层\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // 16),  # 线性变换层，减小通道数\n",
    "            nn.ReLU(inplace=True),  # ReLU 激活函数\n",
    "            nn.Linear(in_channels // 16, in_channels),  # 线性变换层，恢复通道数\n",
    "            nn.Sigmoid()  # Sigmoid 激活函数，产生通道注意力权重\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        # 全局平均池化，将特征图变成全局平均值\n",
    "        x_global = self.global_avgpool(x).view(b, c)\n",
    "\n",
    "        # 通道注意力：通过线性变换和 Sigmoid 操作产生通道权重\n",
    "        x_channel_att = self.channel_attention(x_global).view(b, c, 1, 1)\n",
    "\n",
    "        # 将输入特征图按通道加权\n",
    "        x = x * x_channel_att\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义 LinearBottleNeck_1 模块\n",
    "class LinearBottleNeck_1(nn.Module):\n",
    "    def __init__(self, in_c, out_c, s, t):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c * t, 1),  # 1x1 卷积层，升维操作\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "\n",
    "            nn.Conv2d(in_c * t, in_c * t, 3, stride=s, padding=1, groups=in_c * t),  # 3x3 深度可分离卷积\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "\n",
    "            nn.Conv2d(in_c * t, in_c * t, 1, stride=1, padding=0, groups=1),  # 1x1 卷积层\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "\n",
    "            nn.Conv2d(in_c * t, out_c, 1),  # 1x1 卷积层，降维操作\n",
    "            nn.BatchNorm2d(out_c)  # 批归一化\n",
    "        )\n",
    "\n",
    "        self.stride = s  # 步长\n",
    "        self.in_channels = in_c  # 输入通道数\n",
    "        self.out_channels = out_c  # 输出通道数\n",
    "\n",
    "        # 添加全局注意力模块\n",
    "        self.attention = GAM_Attention(out_c)  # 使用定义的全局注意力模块\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
    "            residual += x  # 恒等映射，如果步长为1且通道数不变，则加上原始输入\n",
    "\n",
    "        # 应用全局注意力\n",
    "        residual = self.attention(residual)\n",
    "\n",
    "        return residual\n",
    "\n",
    "\n",
    "# 定义 LinearBottleNeck_2 模块\n",
    "class LinearBottleNeck_2(nn.Module):\n",
    "    def __init__(self, in_c, out_c, s, t):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c * t, 1),  # 1x1 卷积层，升维操作\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "\n",
    "            nn.Conv2d(in_c * t, in_c * t, 3, stride=s, padding=1, groups=in_c * t),  # 3x3 深度可分离卷积\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "\n",
    "            nn.Conv2d(in_c * t, in_c * t, 1, stride=1, padding=0, groups=1),  # 1x1 卷积层\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "\n",
    "            nn.Conv2d(in_c * t, out_c, 1),  # 1x1 卷积层，降维操作\n",
    "            nn.BatchNorm2d(out_c)  # 批归一化\n",
    "        )\n",
    "\n",
    "        self.residual_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c * t, 1),  # 1x1 卷积层，升维操作\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "\n",
    "            nn.Conv2d(in_c * t, in_c * t, 5, stride=s, padding=2, groups=in_c * t),  # 5x5 深度可分离卷积\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "\n",
    "            nn.Conv2d(in_c * t, in_c * t, 1, stride=1, padding=0, groups=1),  # 1x1 卷积层\n",
    "            nn.BatchNorm2d(in_c * t),  # 批归一化\n",
    "\n",
    "            nn.Conv2d(in_c * t, out_c, 1),  # 1x1 卷积层，降维操作\n",
    "            nn.BatchNorm2d(out_c)  # 批归一化\n",
    "        )\n",
    "\n",
    "        self.residual_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 1, stride=2),  # 1x1 卷积层，步长为2，降维操作\n",
    "            nn.BatchNorm2d(out_c)  # 批归一化\n",
    "        )\n",
    "\n",
    "        self.stride = s  # 步长\n",
    "        self.in_channels = in_c  # 输入通道数\n",
    "        self.out_channels = out_c  # 输出通道数\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        residual_1 = self.residual_1(x)\n",
    "        residual_2 = self.residual_2(x)\n",
    "\n",
    "        # 多尺度特征融合\n",
    "        out_feature = residual_1 + residual + residual_2\n",
    "\n",
    "        return out_feature\n",
    "\n",
    "# 定义 DAMNet\n",
    "\n",
    "class DAMNet(nn.Module):\n",
    "    def __init__(self, class_num=2):\n",
    "        super().__init__()\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),  # 第一层卷积\n",
    "            nn.BatchNorm2d(32),  # 批归一化\n",
    "            nn.ReLU6(inplace=True),  # ReLU6 激活函数\n",
    "        )\n",
    "\n",
    "        self.stage1 = LinearBottleNeck_1(32, 16, 1, 1)  # 第一个模块\n",
    "        self.stage2 = self.make_stage(2, 16, 24, 2, 6)  # 第二个模块\n",
    "        self.stage3 = self.make_stage(3, 24, 32, 2, 6)  # 第三个模块\n",
    "        self.stage4 = self.make_stage(4, 32, 64, 2, 6)  # 第四个模块\n",
    "        self.stage5 = self.make_stage(3, 64, 96, 1, 6)  # 第五个模块\n",
    "        self.stage6 = self.make_stage(3, 96, 160, 2, 6)  # 第六个模块\n",
    "        self.stage7 = LinearBottleNeck_1(160, 320, 1, 6)  # 第七个模块\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(320, 1280, 1),  # 1x1 卷积层\n",
    "            nn.BatchNorm2d(1280),  # 批归一化\n",
    "            nn.ReLU6(inplace=True)  # ReLU6 激活函数\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1280, class_num, 1)  # 输出分类结果\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def make_stage(self, repeat, in_c, out_c, s, t):\n",
    "        layers = []\n",
    "        if s == 1:\n",
    "            layers.append(LinearBottleNeck_1(in_c, out_c, s, t))\n",
    "        else:\n",
    "            layers.append(LinearBottleNeck_2(in_c, out_c, s, t))\n",
    "\n",
    "        while repeat - 1:\n",
    "            layers.append(LinearBottleNeck_1(out_c, out_c, 1, t))\n",
    "            repeat -= 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader):\n",
    "# Assuming 'net' is your model instance\n",
    "    # 检查是否有可用的 GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = DAMNet( class_num=2)\n",
    "    net.to(device)\n",
    "    # 加载预训练权重\n",
    "    pretrained_weights_path = '/home/raytrack/.jupyter/Dynamic/newmodel_weights.pth'\n",
    "    pretrained_dict = torch.load(pretrained_weights_path)\n",
    "\n",
    "    # 获取模型的现有权重字典\n",
    "    model_dict = net.state_dict()\n",
    "\n",
    "    # 过滤掉不匹配的权重\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "\n",
    "    # 更新现有的模型权重字典\n",
    "    model_dict.update(pretrained_dict)\n",
    "\n",
    "    # 加载过滤后的权重字典\n",
    "    net.load_state_dict(model_dict, strict=False)\n",
    "    \n",
    "    #opt = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=0.001)\n",
    "    #opt = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma= 0.985)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(opt, \n",
    "    #                                               base_lr=LR, \n",
    "    #                                               max_lr=0.001, \n",
    "    #                                               step_size_up=100,\n",
    "    #                                               cycle_momentum=False)\n",
    "    opt  = torch.optim.AdamW(net.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=50)\n",
    "    LOSS_WEIGHTS = torch.tensor([1., 1.]) \n",
    "    loss_fcn = torch.nn.CrossEntropyLoss(weight=LOSS_WEIGHTS.to(device))\n",
    "    #loss_fcn = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.0]).to(device))    \n",
    "    t = trange(EPOCHS, desc=' ', leave=True)\n",
    "\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "    pred_result = []\n",
    "    old_acc = 0\n",
    "    old_auc = 0\n",
    "    test_acc = 0\n",
    "    best_epoch = 0\n",
    "    test_performance = []\n",
    "    for e in t:    \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        val_y_true = []\n",
    "        val_y_pred = []                \n",
    "        \n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # training\n",
    "        net.train()\n",
    "        for step, (img, label, _) in enumerate(train_dataloader):\n",
    "            img = img.float().to(device)\n",
    "            label = label.long().to(device)\n",
    "            opt.zero_grad()\n",
    "            out = net(img)\n",
    "            loss = loss_fcn(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            label = label.cpu().detach()\n",
    "            out = out.cpu().detach()\n",
    "            y_true, y_pred = UT.assemble_labels(step, y_true, y_pred, label, out)        \n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss/(step+1)\n",
    "        acc = float(torch.sum(torch.max(y_pred, 1)[1]==y_true))/ float(len(y_pred))\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred[:,1])\n",
    "        f1 = metrics.f1_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        precision = metrics.precision_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        recall = metrics.recall_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        ap = metrics.average_precision_score(y_true, torch.max(y_pred, 1)[1]) #average_precision\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # val\n",
    "        net.eval()\n",
    "        full_path = []\n",
    "        with torch.no_grad():\n",
    "            for step, (img, label, _) in enumerate(val_dataloader):\n",
    "                img = img.float().to(device)\n",
    "                label = label.long().to(device)\n",
    "                out = net(img)\n",
    "                loss = loss_fcn(out, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                label = label.cpu().detach()\n",
    "                out = out.cpu().detach()\n",
    "                val_y_true, val_y_pred = UT.assemble_labels(step, val_y_true, val_y_pred, label, out)\n",
    "                \n",
    "                for item in _:\n",
    "                    full_path.append(item)\n",
    "                \n",
    "        val_loss = val_loss/(step+1)\n",
    "        val_acc = float(torch.sum(torch.max(val_y_pred, 1)[1]==val_y_true))/ float(len(val_y_pred))\n",
    "        val_auc = metrics.roc_auc_score(val_y_true, val_y_pred[:,1])\n",
    "        val_f1 = metrics.f1_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_precision = metrics.precision_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_recall = metrics.recall_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_ap = metrics.average_precision_score(val_y_true, torch.max(val_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "\n",
    "        train_hist.append([train_loss, acc, auc, f1, precision, recall, ap])\n",
    "        val_hist.append([val_loss, val_acc, val_auc, val_f1, val_precision, val_recall, val_ap])             \n",
    "\n",
    "        t.set_description(\"Epoch: %i, train loss: %.4f, train acc: %.4f, val loss: %.4f, val acc: %.4f, test acc: %.4f\" \n",
    "                          %(e, train_loss, acc, val_loss, val_acc, test_acc))\n",
    "\n",
    "\n",
    "        if(old_acc<val_acc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "        \n",
    "        if(old_acc==val_acc) and (old_auc<val_auc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "    return train_hist, val_hist, test_performance, test_y_true, test_y_pred, full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = '/home/raytrack/.jupyter/Dynamic/Preprocessed'\n",
    "\n",
    "\n",
    "GPU = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "LR = 0.0001\n",
    "LOSS_WEIGHTS = torch.tensor([1., 1.]) \n",
    "\n",
    "device = torch.device('cuda:'+str(GPU) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 199, train loss: 0.0010, train acc: 1.0000, val loss: 0.4608, val acc: 0.8421, test acc: 0.9474: 100%|███████████████████████████████████████| 200/200 [08:27<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.7229, train acc: 0.4337, val loss: 0.6943, val acc: 0.5294, test acc: 0.0000:   0%|▏                                          | 1/200 [00:02<08:58,  2.71s/it]/home/raytrack/.conda/envs/torch1121/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 199, train loss: 0.0002, train acc: 1.0000, val loss: 0.3113, val acc: 0.9412, test acc: 0.9412: 100%|███████████████████████████████████████| 200/200 [08:10<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " :   0%|                                                                                                                                                      | 0/200 [00:00<?, ?it/s]/home/raytrack/.conda/envs/torch1121/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 0, train loss: 0.6722, train acc: 0.6076, val loss: 0.6762, val acc: 0.4762, test acc: 0.0000:   0%|                                                   | 0/200 [00:03<?, ?it/s]/home/raytrack/.conda/envs/torch1121/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 199, train loss: 0.0006, train acc: 1.0000, val loss: 0.7989, val acc: 0.8571, test acc: 0.9048: 100%|███████████████████████████████████████| 200/200 [08:54<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89, 0.41318628191947937, 0.9473684210526315, 0.9545454545454545, 0.9411764705882353, 0.8888888888888888, 1.0, 0.8888888888888888], [120, 0.3109762966632843, 0.9411764705882353, 0.9696969696969697, 0.9565217391304348, 0.9166666666666666, 1.0, 0.9166666666666666], [19, 0.1990896463394165, 0.9047619047619048, 0.9818181818181819, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.8740653286107831]]\n",
      "ACC 0.9298, AUC 0.9642, F1 0.9355, Prec 0.9062, Recall 0.9667, AP 0.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#DATA_PATH = '/data/scratch/gliang/data/adni/ADNI2_MRI_Feature/Alex_Layer-9_DynamicImage'\n",
    "#FEATURE_SHAPE=(256,5,5)\n",
    "#print('DATA_PATH:',DATA_PATH)\n",
    "\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "test_performance = []\n",
    "test_y_true = np.asarray([])\n",
    "test_y_pred = np.asarray([])\n",
    "full_path = np.asarray([])\n",
    "for i in range(0, 3):\n",
    "    print('Train Fold', i)\n",
    "    \n",
    "    TEST_NUM = i\n",
    "    TRAIN_LABEL, TEST_LABEL = prep_data(LABEL_PATH, TEST_NUM)\n",
    "    \n",
    "    train_dataset = Dataset_Early_Fusion(label_file=TRAIN_LABEL)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=1, batch_size=BATCH_SIZE , shuffle=True, drop_last=False)\n",
    "\n",
    "    val_dataset = Dataset_Early_Fusion(label_file=TEST_LABEL)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=BATCH_SIZE , shuffle=False, drop_last=False)\n",
    "        \n",
    "    cur_result = train(train_dataloader, val_dataloader)\n",
    "    \n",
    "    train_hist.append(cur_result[0])\n",
    "    val_hist.append(cur_result[1]) \n",
    "    test_performance.append(cur_result[2]) \n",
    "    test_y_true = np.concatenate((test_y_true, cur_result[3].numpy()))\n",
    "    if(len(test_y_pred) == 0):\n",
    "        test_y_pred = cur_result[4].numpy()\n",
    "    else:\n",
    "        test_y_pred = np.vstack((test_y_pred, cur_result[4].numpy()))\n",
    "    full_path = np.concatenate((full_path, np.asarray(cur_result[5])))\n",
    "\n",
    "print(test_performance)\n",
    "\n",
    "test_y_true = torch.tensor(test_y_true)\n",
    "test_y_pred = torch.tensor(test_y_pred)\n",
    "test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true.long()))/ float(len(test_y_pred))\n",
    "test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "\n",
    "print('ACC %.4f, AUC %.4f, F1 %.4f, Prec %.4f, Recall %.4f, AP %.4f' \n",
    "      %(test_acc, test_auc, test_f1, test_precision, test_recall, test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.1",
   "language": "python",
   "name": "torch1121"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
